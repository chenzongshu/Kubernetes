# 背景

日志在问题的排查定位，监控中占有很重要的地位。

在Kubernetes中，日志也有一些新的特色，比如可以输出到Pod的标准输出stdout和stderr，所以来讲讲如何结合经典日志体系架构和容器的特殊性打造日志体系

# 日志系统

下面列举k8s日志系统的注意事项：（其中后三项是k8s特有）

- 如何选择日志等级
- 日志内容规范
- 合理控制日志输出量
- 选择多种日志输出目标
- 控制日志性能消耗

> 1. 确保正常情况下日志的性能消耗不超过整体 CPU 占用的 5%
> 2. 确保日志打印是异步的，不能阻塞业务系统运行

- 如何选择日志库

> 尽可能使用比较流行的日志库的稳定版本，比如Java 使用 Log4J、LogBack；Golang 使用go-kit

- 日志形态选择（*）

> 1. 标准输出只适合比较单一的应用。如果Pod里面有Sidecar之类的容器全部打到一起，就很乱。
> 2. 标准输出性能消耗特别大，实测 10W/s 的日志量会额外占用 Docker 1 个核心的 CPU（单核 100%）

- 日志是否落盘以及落盘介质（*）

> 如果k8s使用远程类型的存储，会额外多 2-3 次网络通信开销，所以一般推荐本地存储

- 如何保证日志存储周期（*）

# k8s日志方案

## 采集

日志的采集方式分为被动采集和主动推送两种，在 K8s 中，被动采集一般分为 Sidecar 和 DaemonSet 两种方式，主动推送有 Docker 推送和业务直写两种方式

### 主动

- 业务直写是在应用中集成日志采集的 SDK，通过 SDK 直接将日志发送到服务端。这种方式省去了落盘采集的逻辑，也不需要额外部署 Agent，对于系统的资源消耗最低，但由于业务和日志 SDK 强绑定，整体灵活性很低，一般只有日志量极大的场景中使用；
- Docker本身具有 LogDriver 功能，可通过配置不同的 LogDriver 将容器的 stdout 通过 DockerEngine 写入到远端存储，以此达到日志采集的目的。这种方式的可定制化、灵活性、资源隔离性都很低，一般不建议在生产环境中使用；

### 被动

- DaemonSet 方式在每个 node 节点上只运行一个日志 agent，采集这个节点上所有的日志。DaemonSet 相对资源占用要小很多，但扩展性、租户隔离性受限，比较适用于功能单一或业务不是很多的集群；
- Sidecar 方式为每个 POD 单独部署日志 agent，这个 agent 只负责一个业务应用的日志采集。Sidecar 相对资源占用较多，但灵活性以及多租户隔离性较强，建议大型的 K8s 集群或作为 PaaS 平台为多个业务方服务的集群使用该方式。

## 日志输出形式

### 标准输出

虽然使用 Stdout 打印日志是 Docker 官方推荐的方式，但大家需要注意：这个推荐是基于容器只作为简单应用的场景，实际的业务场景中我们还是建议大家尽可能使用文件的方式，主要的原因有以下几点：

- Stdout 性能问题，从应用输出 stdout 到服务端，中间会经过好几个流程（例如普遍使用的 JSON LogDriver）：应用 stdout -> DockerEngine -> LogDriver -> 序列化成 JSON -> 保存到文件 -> Agent 采集文件 -> 解析 JSON -> 上传服务端。整个流程相比文件的额外开销要多很多，在压测时，每秒 10 万行日志输出就会额外占用 DockerEngine 1 个 CPU 核；
- Stdout 不支持分类，即所有的输出都混在一个流中，无法像文件一样分类输出，通常一个应用中有 AccessLog、ErrorLog、InterfaceLog（调用外部接口的日志）、TraceLog 等，而这些日志的格式、用途不一，如果混在同一个流中将很难采集和分析；
- Stdout 只支持容器的主程序输出，如果是 daemon/fork 方式运行的程序将无法使用 stdout；
- 文件的 Dump 方式支持各种策略，例如同步/异步写入、缓存大小、文件轮转策略、压缩策略、清除策略等，相对更加灵活。

### 文件

日志打印到文件的方式和虚拟机/物理机基本类似，只是日志可以使用不同的存储方式，例如默认存储、EmptyDir、HostVolume、NFS 等。

注意该方案的问题是**日志不能使用 kubectl logs命令查看**

## 体系

开源体系有EFK/ELK体系，但是实际中要考虑很多：

- 采集agent的资源占用率，达到上限怎么办，格式控制；
- 怎么和CICD集成；
- 日志系统的可靠性和实时性；
- ES性能和资源使用率；
- 多租户怎么隔离；

